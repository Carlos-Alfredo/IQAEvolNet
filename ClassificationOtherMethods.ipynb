{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":36799,"status":"ok","timestamp":1707987418804,"user":{"displayName":"carlos alfredo","userId":"13899691815169459528"},"user_tz":180},"id":"cQZdkE2vjQgZ","outputId":"4b3a365b-f40a-4e62-9a3a-1887a7c182b3"},"outputs":[{"name":"stdout","output_type":"stream","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","import sys\n","import torch\n","\n","drive.mount('/content/drive')\n","\n","sys.path.insert(1,'/content/drive/My Drive/Mestrado/Codigo/Imports/')"]},{"cell_type":"markdown","source":["Select the enhancement algorithm and the dataset folder."],"metadata":{"id":"ksudwdddvKrP"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"T3TpdAfNjWhO"},"outputs":[],"source":["dataset_folder = \"/content/drive/My Drive/Mestrado/Codigo/Datasets/TestCXR/\"\n","dataset = 'TestCXR'\n","enhancement = None\n","#enhancement = 'clahe'\n","#enhancement = 'um'\n","#enhancement = 'hef'\n","#enhancement = 'atace'\n","#enhancement = 'tcdhe'\n","\n","file_folder = [dataset_folder+\"images/Viral Pneumonia/\",\n","               dataset_folder+\"images/Normal/\",\n","               dataset_folder+\"images/Lung_Opacity/\",\n","               dataset_folder+\"images/COVID/\"]"]},{"cell_type":"markdown","source":["Create the dataloader object."],"metadata":{"id":"9WJCL3SbvTFJ"}},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"yp74vG02joEz"},"outputs":[],"source":["from data_loader import folder_data_loader\n","\n","data_loader = folder_data_loader(class_path_list=file_folder, img_size=(224,224), batch_size=32, train_ratio = 0.8, dataset_size_scaling = 1.0, ld_net=enhancement)"]},{"cell_type":"markdown","source":["Create a custom dataloader in a keras format."],"metadata":{"id":"hldD63KuvoX5"}},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"x5QXPXRIjep1"},"outputs":[],"source":["import numpy as np\n","import tensorflow as tf\n","import PIL\n","from inference import image_haze_removal\n","import os\n","import math\n","from torchvision.transforms import ToPILImage\n","from enhancement_algorithms import UM,HEF,CLAHE,ATACE,TCDHE,TCDHE\n","\n","class CustomDataLoader(tf.keras.utils.Sequence):\n","\n","  def __init__(self, folder_data_loader, mode='train'):\n","    self.folder_data_loader = folder_data_loader\n","    self.mode = mode\n","    self.class_representation = folder_data_loader.class_representation\n","\n","  def __len__(self):\n","    return self.folder_data_loader.__len__(mode=self.mode)\n","\n","  def __getitem__(self, idx):\n","    x,y = self.folder_data_loader.get_item(idx,mode=self.mode)\n","    batch_x = []\n","    to_pil = ToPILImage(mode=None)\n","    for i in range(0,x.shape[0]):\n","      image = x[i]\n","      image = to_pil(image*255)\n","      image = image.convert('RGB')\n","      image = np.asarray(image)\n","      image = (image/255.0).astype(np.single)\n","      batch_x.append(image)\n","    batch_x = np.asarray(batch_x)\n","    batch_y = y\n","    return batch_x,batch_y"]},{"cell_type":"markdown","source":["Create the train and validation dataloader."],"metadata":{"id":"4SZSW8Xtvt9P"}},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"sJzvGaEOjyF0"},"outputs":[],"source":["train_dataloader = CustomDataLoader(data_loader,mode='train')\n","\n","validation_dataloader = CustomDataLoader(data_loader,mode='validation')"]},{"cell_type":"markdown","source":["Create the model using transfer learning."],"metadata":{"id":"TdgWr3cFvzz9"}},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"96B3tYnKkbJL"},"outputs":[],"source":["#from keras.applications.inception_v3 import InceptionV3\n","from keras.preprocessing import image\n","from keras.models import Model\n","from keras.layers import Dense, Dropout, Flatten\n","from keras import backend as K\n","from keras import applications\n","from keras.optimizers import SGD\n","import tensorflow as tf\n","\n","batch_size = 32\n","\n","#base_model = applications.vgg19.VGG19(weights='imagenet', include_top=False, input_shape = (224, 224, 3))\n","#classification_folder = '/content/drive/My Drive/Mestrado/Codigo/Classification/TestCXR/other_cnns/vgg/'\n","\n","#base_model = tf.keras.applications.DenseNet121(weights='imagenet', include_top=False, input_shape = (224, 224, 3))\n","#classification_folder = '/content/drive/My Drive/Mestrado/Codigo/Classification/TestCXR/other_cnns/densenet/'\n","\n","#base_model = tf.keras.applications.ResNet152V2(weights='imagenet', include_top=False, input_shape = (224, 224, 3))\n","#classification_folder = '/content/drive/My Drive/Mestrado/Codigo/Classification/TestCXR/other_cnns/resnet/'\n","\n","#base_model = tf.keras.applications.nasnet.NASNetLarge(weights='imagenet', include_top=False, input_shape = (224, 224, 3))\n","#classification_folder = '/content/drive/My Drive/Mestrado/Codigo/Classification/TestCXR/other_cnns/nasnet/'\n","\n","#base_model = tf.keras.applications.xception.Xception(weights='imagenet', include_top=False, input_shape = (224, 224, 3))\n","#classification_folder = '/content/drive/My Drive/Mestrado/Codigo/Classification/TestCXR/other_cnns/xception/'\n","\n","#base_model = tf.keras.applications.inception_v3.InceptionV3(weights='imagenet', include_top=False, input_shape = (224, 224, 3))\n","#classification_folder = '/content/drive/My Drive/Mestrado/Codigo/Classification/TestCXR/other_cnns/inception/'\n","\n","#base_model = tf.keras.applications.inception_resnet_v2.InceptionResNetV2(weights='imagenet', include_top=False, input_shape = (224, 224, 3))\n","#classification_folder = '/content/drive/My Drive/Mestrado/Codigo/Classification/TestCXR/other_cnns/inceptionresnet/'\n","\n","base_model = applications.mobilenet_v2.MobileNetV2(weights='imagenet', include_top=False, input_shape = (224, 224, 3))\n","classification_folder = '/content/drive/My Drive/Mestrado/Codigo/Classification/TestCXR/other_cnns/mobilenet/'\n","\n","base_model.trainable = False\n","x = base_model.input\n","x = base_model(x, training=False)\n","\n","#x = tf.keras.layers.GlobalAveragePooling2D()(x)\n","\n","x = tf.keras.layers.Flatten()(x)\n","x = Dense(128, activation = 'relu')(x)\n","x = tf.keras.layers.Dropout(0.3)(x)\n","\n","predictions = Dense(4, activation = 'softmax')(x)\n","\n","model = Model(inputs=base_model.input, outputs=predictions)\n","\n","model.compile(optimizer=tf.keras.optimizers.SGD(learning_rate=1e-4,momentum=0.9),\n","              loss=tf.keras.losses.CategoricalCrossentropy(),\n","              metrics=[tf.keras.metrics.CategoricalAccuracy(),\n","                       tf.keras.metrics.CategoricalCrossentropy(),\n","                       tf.keras.metrics.Precision()]\n","              )\n","\n","#model.summary()"]},{"cell_type":"markdown","source":["Run the training, save the train and finetune history, and the confusion matrix."],"metadata":{"id":"pHsfWwwxwT3J"}},{"cell_type":"code","source":["class_weight = {}\n","class_representation = train_dataloader.class_representation\n","for i in range(0,class_representation.shape[0]):\n","  class_weight[i] = class_representation.sum()/(class_representation[i]*class_representation.shape[0])\n","\n","print(class_weight)\n","\n","callbacks = [tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=5, verbose=1,restore_best_weights=True)]\n","\n","history1=model.fit(\n","    train_dataloader,\n","    validation_data = validation_dataloader,\n","    batch_size = 32,\n","    epochs = 20,\n","    class_weight=class_weight,\n","    callbacks = callbacks)\n","\n","model.trainable = True\n","model.compile(optimizer=tf.keras.optimizers.SGD(learning_rate=1e-6,momentum=0.9),\n","              loss=tf.keras.losses.CategoricalCrossentropy(),\n","              metrics=[tf.keras.metrics.CategoricalAccuracy(),\n","                       tf.keras.metrics.CategoricalCrossentropy(),\n","                       tf.keras.metrics.Precision()]\n","              )\n","history2=model.fit(\n","    train_dataloader,\n","    validation_data = validation_dataloader,\n","    batch_size = 32,\n","    epochs = 10,\n","    class_weight = class_weight,\n","    callbacks = callbacks)\n","\n","import pickle\n","\n","if ld_net == None:\n","  ld_net = 'None'\n","\n","test_folder = classification_folder\n","\n","with open(test_folder+ld_net+'/trainHistoryDict', 'wb') as file_pi:\n","  pickle.dump(history1.history, file_pi)\n","\n","with open(test_folder+ld_net+'/finetuneHistoryDict', 'wb') as file_pi:\n","  pickle.dump(history2.history, file_pi)\n","\n","model.save_weights(test_folder+ld_net+'/weight'+'.h5')\n","\n","import pandas as pd\n","from sklearn.metrics import confusion_matrix\n","\n","y_pred = (model.predict(x=validation_dataloader,batch_size=32)).argmax(axis=1)\n","\n","y_true = []\n","\n","for i in range(0,validation_dataloader.__len__()):\n","  batch_x,batch_y = validation_dataloader.__getitem__(i)\n","  for j in range(0,batch_y.shape[0]):\n","    y_true.append(batch_y[j])\n","\n","y_true = np.asarray(y_true).argmax(axis=1)\n","\n","conf_matrix = confusion_matrix(y_true[0:y_pred.shape[0]], y_pred)\n","df = pd.DataFrame(conf_matrix)\n","df.to_csv(test_folder+ld_net+'/confusion_matrix'+'.csv')"],"metadata":{"id":"hNplmJOpEGqp"},"execution_count":null,"outputs":[]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"T4","machine_shape":"hm","provenance":[],"authorship_tag":"ABX9TyPhZGP+ri5jI/VdokgH2BJw"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}